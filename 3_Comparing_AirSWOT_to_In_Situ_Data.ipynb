{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79234980",
   "metadata": {},
   "source": [
    "# Delta-X 2022 Applications Workshop\n",
    "\n",
    "# Comparing AirSWOT to In Situ Data\n",
    "\n",
    "Â© 2022 California Institute of Technology. Government sponsorship acknowledged.\n",
    "\n",
    "Author: Michael Denbina, Jet Propulsion Laboratory, California Institute of Technology\n",
    "\n",
    "---\n",
    "\n",
    "The AirSWOT tutorial is split into three modules, which cover:\n",
    "\n",
    "1. AirSWOT Data Introduction\n",
    "2. Estimating Water Surface Elevation and Slope from AirSWOT \n",
    "3. Comparing AirSWOT to In Situ Data (this module)\n",
    "\n",
    "In this module, we will show examples comparing water surface elevations from AirSWOT to in situ data.  We will also show how AirSWOT can be used to estimate the vertical datum offset for in situ data with an unknown datum.  We will also discuss how to convert between the WGS84 and NAVD88 vertical datums.\n",
    "\n",
    "We will begin by importing a number of modules that we need, and then pointing to the location where the data has been downloaded, similar to the first module.\n",
    "\n",
    "**Note**: As in the previous module, you may need to update the variable \"data_path\" and data filenames to point to where the data is located if you have moved the data or downloaded it separately rather than using the sample data included with this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f0e160",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setup Google Colab:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# If you aren't using Google Colab -- skip running this cell.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# For access to Google Drive files\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydrive\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleAuth\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydrive\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdrive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleDrive\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Setup Google Colab:\n",
    "# If you aren't using Google Colab -- skip running this cell.\n",
    "\n",
    "# For access to Google Drive files\n",
    "from google.colab import files\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# For saving to Google Drive\n",
    "from google.colab import drive\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "Gdrive = GoogleDrive(gauth)\n",
    "\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ade869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path pointing to AirSWOT sample data and associated files:\n",
    "data_path = '/content/drive/MyDrive/DeltaX_Workshop_2022/Tutorials/2_AirSWOT'\n",
    "data_path = 'airswot_sample_data'\n",
    "\n",
    "# By default, this is pointing to the location of the data on your Google Drive\n",
    "# (assuming you added a shortcut to the workshop materials).\n",
    "\n",
    "# If you are running on your local machine, update data_path to the location where you\n",
    "# saved the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfec2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module also needs to save some output files!  Please change the path below to\n",
    "# folder where it is OK to write some GeoTIFF files.\n",
    "save_data_path = 'airswot_hgt_navd'\n",
    "\n",
    "# The default path is relative to the location of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b54831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Useful Libraries\n",
    "from datetime import datetime, timedelta # for handling dates and times of station and AirSWOT data\n",
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Filenames of the data we will use in this module, relative to data_path.\n",
    "crms_station_data_file = os.path.join(data_path, 'station_data/CRMS0434-H01_20060217180000-20210929090000_downloaded20211206.csv')\n",
    "calumet_station_data_file = os.path.join(data_path, 'station_data/USGS_Calumet_wl.csv')\n",
    "\n",
    "# AirSWOT Data (copy/pasted from our results in the previous module):\n",
    "airswot_wse = np.array([-25.504597, -25.560078, -25.446281, -25.34314])\n",
    "airswot_datetime = np.array([datetime(2021, 4, 16, 0, 54, 32),\n",
    "                             datetime(2021, 4, 16, 4, 17, 20),\n",
    "                             datetime(2021, 4, 18, 16, 43, 12),\n",
    "                             datetime(2021, 4, 18, 20, 20, 23)])\n",
    "\n",
    "hgt_raster_files = np.array(['L2/utm_m0m_20210326171437.hgt.tif',\n",
    "                             'L2/utm_m0m_20210326194454.hgt.tif',\n",
    "                             'L2/utm_m0m_20210327142430.hgt.tif',\n",
    "                             'L2/utm_m0m_20210327164503.hgt.tif',\n",
    "                             'L2/utm_m0m_20210401124406.hgt.tif',\n",
    "                             'L2/utm_m0m_20210401152540.hgt.tif'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f127e98",
   "metadata": {},
   "source": [
    "We will load the CRMS data into a DataFrame using Pandas.  We will then convert the date and time from the CSV file, which are text strings, into Python datetime objects so that they will be easier to compare with the AirSWOT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30a3e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'airswot_sample_data/station_data/CRMS0434-H01_20060217180000-20210929090000_downloaded20211206.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the CRMS data into Pandas.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m crms \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrms_station_data_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the CRMS DataFrame:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(crms)\n",
      "File \u001b[0;32m~/miniconda3/envs/kapok/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kapok/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kapok/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/kapok/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kapok/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/kapok/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'airswot_sample_data/station_data/CRMS0434-H01_20060217180000-20210929090000_downloaded20211206.csv'"
     ]
    }
   ],
   "source": [
    "# Load the CRMS data into Pandas.\n",
    "crms = pd.read_csv(crms_station_data_file)\n",
    "\n",
    "# Print the CRMS DataFrame:\n",
    "print(crms)\n",
    "\n",
    "# Print the columns (field names) of the DataFrame:\n",
    "print(crms.columns)\n",
    "\n",
    "# Conversion factor from feet to meters.  (CRMS station water levels are in feet.)\n",
    "feet_to_meters = 0.3048\n",
    "\n",
    "# Load the height from the CRMS data and convert it to meters.\n",
    "crms_hgt = np.array(crms['Raw Water Level (ft)']) * feet_to_meters\n",
    "\n",
    "# Load the dates and times.\n",
    "dates = np.array(crms['Date (mm/dd/yyyy)'])\n",
    "times = np.array(crms['Time (hh:mm:ss)'])\n",
    "\n",
    "# Track the number of CRMS data records and create an array to store the dates and times as integers.\n",
    "num_of_records = len(date)\n",
    "datetime_int = np.zeros((num_of_records, 5), dtype='int')\n",
    "\n",
    "# Loop through the dates and times, converting each part (e.g. year, month, day, hour, minute) into an integer.\n",
    "for num, (date_str, time_str) in enumerate(zip(dates, times)):\n",
    "    date_str = date_str.split('/')\n",
    "    datetime_int[num, 0] = int(date_str[2])\n",
    "    datetime_int[num, 1] = int(date_str[0])\n",
    "    datetime_int[num, 2] = int(date_str[1])\n",
    "    \n",
    "    time_str = time_str.split(':')\n",
    "    datetime_int[num, 3] = int(time_str[0])\n",
    "    datetime_int[num, 4] = int(time_str[1])\n",
    "\n",
    "\n",
    "# The CRMS data is in Central time, while the AirSWOT data is in UTC.\n",
    "# We must therefore either shift the CRMS data forward by five hours, or the AirSWOT data back.\n",
    "# We will shift the CRMS data forward:\n",
    "time_shift = timedelta(hours=5)\n",
    "\n",
    "# Convert the dates and times to Python datetime objects.\n",
    "crms_datetime = np.empty((num_of_records), dtype=datetime)\n",
    "for num in range(datetime_int.shape[0]):\n",
    "    crms_datetime[num] = datetime(datetime_int[num, 0], datetime_int[num, 1], datetime_int[num, 2], datetime_int[num, 3], datetime_int[num, 4], 0) + time_shift\n",
    "\n",
    "# We do not care about all of the CRMS data in the file.\n",
    "# Let us only consider the period of five days around the time of the AirSWOT acquisition.\n",
    "start_datetime = datetime(2021, 4, 15, 0, 0, 0)\n",
    "end_datetime = datetime(2021, 4, 20, 0, 0, 0)\n",
    "date_range = (crms_datetime < end_datetime) & (crms_datetime > start_datetime)\n",
    "\n",
    "# Subset the CRMS data to the desired date range.\n",
    "crms_datetime = crms_datetime[date_range]\n",
    "crms_hgt = crms_hgt[date_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b6ee4",
   "metadata": {},
   "source": [
    "Let's plot the CRMS and AirSWOT data on the same plot, to compare their water surface elevation values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a13fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the CRMS time series and AirSWOT data.\n",
    "plt.figure()\n",
    "plt.plot(crms_datetime, crms_hgt, 'g-', label='CRMS 0434')\n",
    "plt.plot(airswot_datetime, airswot_wse, 'b+', markersize=12, label='AirSWOT')\n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%m %d')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "plt.title('AirSWOT and CRMS WSE vs. Time')\n",
    "plt.legend(loc='upper right', frameon=True, fontsize=8)\n",
    "xlbl = plt.xlabel('UTC Date')\n",
    "ylbl = plt.ylabel('Water Surface Elevation (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46022ead",
   "metadata": {},
   "source": [
    "There is a very large difference between the water levels reported by CRMS and AirSWOT!  But why?\n",
    "\n",
    "Actually, this is expected, because the AirSWOT data and the CRMS data are in different vertical datums.  That is, their elevations are referenced to different surfaces.\n",
    "\n",
    "The AirSWOT data is with respect to the WGS84 ellipsoid, while the CRMS data that we loaded is raw gauge data and therefore records elevations relative to the position of the water level gauge, rather than to a geoid or ellipsoid surface.\n",
    "\n",
    "One of the useful applications of AirSWOT is that we can estimate the datum of a gauge by calculating the difference between AirSWOT and gauge data.  We will do this now, estimating the vertical datum of the CRMS station using AirSWOT, and then comparing that to the height of the NAVD88 geoid at the station location, to see if our conversion factor is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helpful function will interpolate the CRMS station data to the same time as the AirSWOT data.\n",
    "def interpolate_station_wl(station_datetime, station_wl, interpolated_utc):\n",
    "    \"\"\" Interpolate the given station water level timeseries to the desired UTC datetime. \"\"\"\n",
    "    # Convert datetimes in station data to time after first record:\n",
    "    wl_series = np.array(station_wl, dtype='float32')\n",
    "    datetime_series = np.array(station_datetime, dtype=datetime)\n",
    "    timedelta_series = (datetime_series - datetime_series[0]).astype(timedelta)\n",
    "    timedelta_series = np.ravel(timedelta_series)\n",
    "\n",
    "    interpolated_timedelta = interpolated_utc - station_datetime[0]\n",
    "\n",
    "    # Convert timedeltas to floating point seconds.\n",
    "    timedelta_series /= timedelta(seconds=1)\n",
    "    timedelta_series = timedelta_series.astype('int64')\n",
    "    interpolated_timedelta /= timedelta(seconds=1)\n",
    "    \n",
    "\n",
    "    # Interpolate water levels at requested datetime.\n",
    "    interpolated_wl = np.interp(interpolated_timedelta, timedelta_series, wl_series)\n",
    "    return interpolated_wl\n",
    "\n",
    "\n",
    "# Interpolate the station water levels at the AirSWOT acquisition times:\n",
    "wse_difference = np.zeros((4), dtype='float32')\n",
    "for num, dt in enumerate(airswot_datetime):\n",
    "    station_wse_interpolated_to_airswot = interpolate_station_wl(crms_datetime, crms_hgt, dt)\n",
    "    wse_difference[num] = airswot_wse[num] - station_wse_interpolated_to_airswot\n",
    "\n",
    "print('AirSWOT - CRMS Water Level Differences:')\n",
    "print(wse_difference)\n",
    "print('')\n",
    "print('Median AirSWOT - CRMS Water Level Difference: {:.2f} m'.format(np.median(wse_difference)))\n",
    "print('Std. Dev. of AirSWOT - CRMS Water Level Differences: {:.2f} m'.format(np.std(wse_difference)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686eddd",
   "metadata": {},
   "source": [
    "According to this estimate, to convert the station data to have the same vertical datum as AirSWOT (the WGS84 ellipsoid), we need to subtract 25.98 m from the CRMS station data.  Let's do that now and look at the updated plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(crms_datetime, crms_hgt - 25.98, 'g-', label='CRMS 0434')\n",
    "plt.plot(airswot_datetime, airswot_wse, 'b+', markersize=12, label='AirSWOT')\n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%m %d')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "plt.title('AirSWOT and CRMS WSE vs. Time')\n",
    "plt.legend(loc=0, frameon=True, fontsize=8)\n",
    "xlbl = plt.xlabel('UTC Date')\n",
    "ylbl = plt.ylabel('Water Surface Elevation (m, WGS84)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4c9aa",
   "metadata": {},
   "source": [
    "When doing this procedure, if the AirSWOT elevations are incorrect, then of course we will get the wrong datum adjustment.  But we can be more confident in the AirSWOT estimates when the difference between AirSWOT and the station data is consistent over time between different flights and flight lines, such as in the above.  Even if the absolute WSE calibration is off by a few cm, AirSWOT and the CRMS station data both record the same change in water level between the times of the AirSWOT acquisitions.\n",
    "\n",
    "Remember that I said we were using the raw gauge data from the CRMS station, not referenced to a datum?  While that is true in general, for this particular station, it so happens that the raw gauge elevation data is very close to the NAVD88 geoid.\n",
    "\n",
    "One way to convert between vertical datums easily is to use the NOAA tool vDatum, which can be found at the following website: [NOAA VDatum](https://vdatum.noaa.gov/).\n",
    "\n",
    "There is both a downloadable tool, as well as an online tool.  For the sake of convenience, we'll use the online tool in this application, which can be found here: [NOAA VDatum Online Conversion](https://vdatum.noaa.gov/vdatumweb/).\n",
    "\n",
    "To calculate the difference in vertical datum between the WGS84 ellipsoid and the NAVD88 geoid, we need to know the location of the station.  This data is included in the CRMS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = crms['Latitude'][0]\n",
    "longitude = crms['Longitude'][0]\n",
    "print('CRMS Latitude: {}'.format(latitude))\n",
    "print('CRMS Longitude: {}'.format(longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df520f38",
   "metadata": {},
   "source": [
    "Now let's use this latitude and longitude to calculate the difference between the WGS84 and NAVD88 vertical datums:\n",
    "\n",
    "![NOAA VDatum Step One](images/noaa_vdatum_step1.png)\n",
    "\n",
    "When you click the \"Transform\" button, you will be prompted to specify the input and output dates.  This is because the transformation between the datums varies not only spatially but also over time.  In truth, we don't really know when the input position for the station data was surveyed, but we'll put \"2021.0\" for both the input and output dates:\n",
    "\n",
    "![NOAA VDatum Step One](images/noaa_vdatum_step2.png)\n",
    "\n",
    "Note that there is a small change in the output position, not just the output height.  However, this change in horizontal position will tend to be small when converting between WGS84 and NAD83/NAVD88.  This change in horizontal position can be ignored in this case, as it will be less than the spatial resolution of the AirSWOT data.\n",
    "\n",
    "However, the change in vertical height is substantial, and must be considered.  In this case, VDatum reports that the height difference from WGS84 to NAVD88 is 25.948 m.\n",
    "\n",
    "This is very close to the 25.98 m we calculated from AirSWOT.  These are within a few cm, so are within the expected error level of AirSWOT.  There are other reasons that can explain these small differences as well, such as the fact that we calculated the water surface elevation centered around the lake, but the CRMS station is actually located in a side channel near the lake.  Since the water is connected, they should be at a similar height, but a small difference in water level between the lake and the channel is possible.\n",
    "\n",
    "Finally, let's plot the water levels again, this time using the conversion factor from VDatum.  In this case, we aill add the conversion factor to the AirSWOT water levels, so that the plot this time will be with respect to the NAVD88 geoid rather than the WGS84 ellipsoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e72902",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(crms_datetime, crms_hgt, 'g-', label='CRMS 0434')\n",
    "plt.plot(airswot_datetime, airswot_wse + 25.948, 'b+', markersize=12, label='AirSWOT')\n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%m %d')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "plt.title('AirSWOT and CRMS WSE vs. Time')\n",
    "plt.legend(loc=0, frameon=True, fontsize=8)\n",
    "xlbl = plt.xlabel('UTC Date')\n",
    "ylbl = plt.ylabel('Water Surface Elevation (m, NAVD88)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd397bb2",
   "metadata": {},
   "source": [
    "## Converting the Vertical Datum of AirSWOT L2 Products\n",
    "\n",
    "So far, we have demonstrated how to convert the vertical datum of a single point such as a water level station.  However, what if we want to convert an entire L2 AirSWOT product from WGS84 to the NAVD88 vertical datum.\n",
    "\n",
    "We can do this using GDAL, as illustrated in the following example.  This time, we will go back to the Atchafalaya Basin, to the same flight line we used in the first module, to demonstrate the conversion.\n",
    "\n",
    "If you have errors running the below example, one reason can be that your GDAL installation cannot find the geoid grid file \"g2012bu0.gtx\" specified below.  In that case, you can download geoid GTX files from the following link: [NAVD88 GEOID12B](http://download.osgeo.org/proj/vdatum/usa_geoid2012b.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_options = gdal.WarpOptions(format='GTiff',\n",
    "                                srcSRS='+proj=utm +zone=15 +datum=WGS84 +units=m +no_defs',\n",
    "                                dstSRS='+proj=utm +zone=15 +datum=WGS84 +units=m +no_defs +geoidgrids=g2012bu0.gtx')\n",
    "\n",
    "for hgt_file_wgs84 in hgt_raster_files:\n",
    "    print('Converting vertical datum of file \"{}\"...'.format(hgt_file))\n",
    "    hgt_file_navd = os.path.basename(hgt_file_wgs84).split('.')[0] + '.hgt_navd.tif'\n",
    "    hgt_file_navd = os.path.join(save_data_path, hgt_file_navd)\n",
    "    navd_hgt = gdal.Warp(hgt_file_navd, os.path.join(data_path, hgt_file_wgs84), options=warp_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d94ec",
   "metadata": {},
   "source": [
    "The above code should have generated files with names ending in \".hgt_navd.tif\" in addition to the original \".hgt.tif\" files.  If you load these \".hgt_navd.tif\" files in QGIS, you should see that the elevation values are closer to zero now that they are referenced to the geoid rather than to the WGS84 ellipsoid.\n",
    "\n",
    "We will now reuse code from the previous module in order to derive AirSWOT water surface elevation estimates near the USGS Calumet water level station, which is located in the Wax Lake Outlet, upstream of the Intracoastal Waterway.  The USGS Calumet station data included in the sample data for this tutorial was downloaded [here](https://waterdata.usgs.gov/nwis/uv?site_no=07381590)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got the latitude and longitude position of the Calumet station from the above link,\n",
    "# then converted it to UTM coordinates using VDatum.\n",
    "x_calumet = 657426.03200 # X coordinate position of the USGS Calumet station, in UTM Zone 15 North.\n",
    "y_calumet = 3286405.15100 # Y coordinate position of the USGS Calumet station.\n",
    "\n",
    "hgt_raster_files_navd = np.array(['utm_m0m_20210326171437.hgt_navd.tif',\n",
    "                                  'utm_m0m_20210326194454.hgt_navd.tif',\n",
    "                                  'utm_m0m_20210327142430.hgt_navd.tif',\n",
    "                                  'utm_m0m_20210327164503.hgt_navd.tif',\n",
    "                                  'utm_m0m_20210401124406.hgt_navd.tif',\n",
    "                                  'utm_m0m_20210401152540.hgt_navd.tif'])\n",
    "\n",
    "\n",
    "# Helper functions from the previous module.\n",
    "def nearest_interpolate(data, x, y, nodataval=np.nan):\n",
    "    \"\"\"Function to perform nearest neighbor interpolation on the input array\n",
    "        data, at the image coordinates given by input arguments x and y.\n",
    "\n",
    "    Arguments\n",
    "        data (array): 2D array containing raster data to interpolate.\n",
    "        x (array): the X coordinate values at which to interpolate (in array\n",
    "            indices, starting at zero).  Note that X refers to the second\n",
    "            dimension of data (e.g., the columns).\n",
    "        y (array): the Y coordinate values at which to interpolate (in array\n",
    "            indices, starting at zero).  Note that Y refers to the first\n",
    "            dimension of data (e.g., the rows).\n",
    "        nodataval: No data value for points outside of the data bounds.\n",
    "\n",
    "    Returns:\n",
    "        intdata (array): The 2D interpolated array, with same dimensions as\n",
    "            x and y.\n",
    "\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    x = np.round(x).astype('int32')\n",
    "    y = np.round(y).astype('int32')\n",
    "\n",
    "    ind = (x < 0) | (y < 0) | (x >= data.shape[1]) | (y >= data.shape[0])\n",
    "\n",
    "    if np.any(ind):\n",
    "        x[ind] = 0\n",
    "        y[ind] = 0\n",
    "\n",
    "    intdata = (data[y, x]).astype('float32')\n",
    "\n",
    "    if np.any(ind):\n",
    "        intdata[ind] = nodataval\n",
    "\n",
    "    return intdata\n",
    "\n",
    "\n",
    "def interp_raster_at_xy(data, geo_transform, x, y):\n",
    "    \"\"\" Interpolate values of raster at input coordinates using nearest\n",
    "        neighbor interpolation. \"\"\"\n",
    "    # Calculate the image coordinates from the given map coordinates:\n",
    "    rows, columns = calculate_image_coords(x, y, geo_transform)\n",
    "    \n",
    "    # Calculate the mask value at the given coordinates using nearest neighbor interpolation:\n",
    "    ds_interp = nearest_interpolate(data, columns, rows)\n",
    "    return ds_interp\n",
    "\n",
    "\n",
    "def get_coords_of_image_chip(geo_transform, rows, cols):\n",
    "    \"\"\" Calculate the map coordinates for a given image chip using\n",
    "        the geo_transform and image coordinates of that chip. \"\"\"\n",
    "    x_coords = cols*geo_transform[1] + geo_transform[0]\n",
    "    y_coords = rows*geo_transform[5] + geo_transform[3]\n",
    "    return x_coords, y_coords\n",
    "\n",
    "\n",
    "def calculate_image_coords(x_coord, y_coord, geo_transform):\n",
    "    x_origin = geo_transform[0]\n",
    "    y_origin = geo_transform[3]\n",
    "    x_spacing = geo_transform[1]\n",
    "    y_spacing = geo_transform[5]\n",
    "    \n",
    "    row = (y_coord - y_origin) / y_spacing\n",
    "    column = (x_coord - x_origin) / x_spacing\n",
    "    \n",
    "    return row, column\n",
    "\n",
    "\n",
    "def filter_points_mad(z, thresh=2):\n",
    "    # Remove height outliers.\n",
    "    if np.any(np.isfinite(z)):\n",
    "        med = np.nanmedian(z)\n",
    "        abs_dev = np.abs(z - med)\n",
    "        left_mad = np.nanmedian(abs_dev[z <= med])\n",
    "        right_mad = np.nanmedian(abs_dev[z >= med])\n",
    "\n",
    "        z_mad = left_mad * np.ones(z.shape)\n",
    "        z_mad[z > med] = right_mad\n",
    "\n",
    "        h_score = 0.6745 * abs_dev / z_mad\n",
    "        h_score[z == med] = 0\n",
    "\n",
    "        ind = (h_score <= thresh) & np.isfinite(z)\n",
    "    else:\n",
    "        ind = np.isfinite(z)\n",
    "\n",
    "    return ind\n",
    "\n",
    "\n",
    "# Load the water mask.\n",
    "water_mask_file = os.path.join(data_path, 'water_mask/Sentinel2_DOS_mosaic_sub_EVI_mask.tif')\n",
    "water_mask = gdal.Open(water_mask_file)\n",
    "water_mask_data = water_mask.ReadAsArray()\n",
    "water_mask_geo = water_mask.GetGeoTransform()\n",
    "\n",
    "# Empty arrays to store the WSE and datetimes.\n",
    "airswot_wse = np.array([], dtype='float32')\n",
    "airswot_datetime = np.array([], dtype=datetime)\n",
    "airswot_hgt_stack = None\n",
    "airswot_hgt_stack_masked_filtered = None\n",
    "\n",
    "# Loop through the AirSWOT L2 rasters, calculating the water surface elevation of the lake for each raster.\n",
    "for file in hgt_raster_files_navd:\n",
    "    hgt_product = gdal.Open(os.path.join(save_data_path, file))\n",
    "    hgt_product_data = hgt_product.ReadAsArray()\n",
    "    hgt_product_data[hgt_product_data == -10000] = np.nan # Values of -10000 represent void data.\n",
    "    hgt_product_geo = hgt_product.GetGeoTransform()\n",
    "    \n",
    "    # Calculate the AirSWOT image coordinates corresponding to the lake:\n",
    "    row_station, column_station = calculate_image_coords(x_calumet, y_calumet, hgt_product_geo)\n",
    "    \n",
    "    # Subset the AirSWOT data to an image chip containing the USGS Calumet station and surrounding area:\n",
    "    row_station_int = int(row_station)\n",
    "    column_station_int = int(column_station)\n",
    "    hgt_station_chip = hgt_product_data[row_station_int-200:row_station_int+201,\n",
    "                                        column_station_int-200:column_station_int+201]\n",
    "\n",
    "    # Calculate the row and column image coordinates for each pixel in the AirSWOT image chip.\n",
    "    rows_station_chip = np.arange(row_station_int-200, row_station_int+201)\n",
    "    columns_station_chip = np.arange(column_station_int-200, column_station_int+201)\n",
    "    rows_station_chip = np.tile(rows_station_chip, (len(columns_station_chip), 1)).T\n",
    "    columns_station_chip = np.tile(columns_station_chip, (len(rows_station_chip), 1))\n",
    "    \n",
    "    # Calculate the X and Y UTM coordinates for each pixel in the AirSWOT image chip.\n",
    "    x_station_chip, y_station_chip = get_coords_of_image_chip(hgt_product_geo, rows_station_chip, columns_station_chip)\n",
    "\n",
    "    # Interpolate the value of the water mask at the desired coordinates:\n",
    "    water_mask_lake_chip = interp_raster_at_xy(water_mask_data, water_mask_geo, x_station_chip, y_station_chip)\n",
    "    water_mask_lake_chip = water_mask_lake_chip > 0\n",
    "    \n",
    "    # Mask the AirSWOT height data:\n",
    "    hgt_station_chip_masked = hgt_station_chip.copy()\n",
    "    hgt_station_chip_masked[~water_mask_lake_chip] = np.nan\n",
    "\n",
    "    # Apply the outlier filter:\n",
    "    indices_to_keep = filter_points_mad(hgt_station_chip_masked)\n",
    "    hgt_station_chip_masked_filtered = hgt_station_chip_masked.copy()\n",
    "    hgt_station_chip_masked_filtered[~indices_to_keep] = np.nan\n",
    "    \n",
    "    # Calculate the water surface elevation as the mean height in the masked water data.\n",
    "    # Only calculate the WSE if at least 100 pixels containing height data are in the window.\n",
    "    if np.sum(np.isfinite(hgt_station_chip_masked_filtered)) > 100:\n",
    "        temp_wse = np.nanmean(hgt_station_chip_masked_filtered)\n",
    "    else:\n",
    "        temp_wse = np.nan\n",
    "    \n",
    "    # Let's also parse the AirSWOT product filename to a datetime:\n",
    "    datetime_string = file.split('_')[2].split('.')[0]\n",
    "    year = int(datetime_string[0:4])\n",
    "    month = int(datetime_string[4:6])\n",
    "    day = int(datetime_string[6:8])\n",
    "    hour = int(datetime_string[8:10])\n",
    "    minute = int(datetime_string[10:12])\n",
    "    second = int(datetime_string[12:14])\n",
    "    \n",
    "    temp_datetime = datetime(year=year, month=month, day=day, hour=hour, minute=minute, second=second)\n",
    "    \n",
    "    # Append the values for this flight line to the arrays:\n",
    "    airswot_wse = np.append(airswot_wse, temp_wse)\n",
    "    airswot_datetime = np.append(airswot_datetime, temp_datetime)\n",
    "    \n",
    "    if airswot_hgt_stack is None:\n",
    "        airswot_hgt_stack = hgt_station_chip[np.newaxis, :, :]\n",
    "        airswot_hgt_stack_masked_filtered = hgt_station_chip_masked_filtered[np.newaxis, :, :]\n",
    "    else:\n",
    "        airswot_hgt_stack = np.append(airswot_hgt_stack, hgt_station_chip[np.newaxis, :, :], axis=0)\n",
    "        airswot_hgt_stack_masked_filtered = np.append(airswot_hgt_stack_masked_filtered, hgt_station_chip_masked_filtered[np.newaxis, :, :], axis=0)\n",
    "        \n",
    "\n",
    "# Print the results:\n",
    "for num in range(len(airswot_wse)):\n",
    "    print('At {}, the AirSWOT WSE at Calumet was {:.2f} m with respect to the NAVD88 geoid.'.format(airswot_datetime[num], airswot_wse[num]))\n",
    "\n",
    "# Plot the water surface elevation time series:\n",
    "plt.figure()\n",
    "plt.plot(airswot_datetime, airswot_wse, 'b+')\n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%m %d')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "plt.title('AirSWOT WSE vs. Time')\n",
    "xlbl = plt.xlabel('UTC Date')\n",
    "ylbl = plt.ylabel('AirSWOT Water Surface Elevation (m, NAVD88)')\n",
    "\n",
    "\n",
    "# Plot the AirSWOT height image chip used to calculate the WSE for each flightline, before and after filtering.\n",
    "plt.figure(figsize=(15,6))\n",
    "for num in range(len(airswot_wse)):\n",
    "    plt.subplot(1, 6, num+1)\n",
    "    plt.imshow(airswot_hgt_stack[num], vmin=0, vmax=2)\n",
    "    plt.plot(200, 200, 'r.', markersize=18)\n",
    "    plt.title(airswot_datetime[num])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "for num in range(len(airswot_wse)):\n",
    "    plt.subplot(1, 6, num+1)\n",
    "    plt.imshow(airswot_hgt_stack_masked_filtered[num], vmin=0, vmax=2)\n",
    "    plt.plot(200, 200, 'r.', markersize=18)\n",
    "    plt.title(airswot_datetime[num])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8739a",
   "metadata": {},
   "source": [
    "The AirSWOT water surface elevations that we calculated are now closer to zero, since we are using a vertical datum referenced to the NAVD88 geoid rather than the WGS84 ellipsoid.\n",
    "\n",
    "As well, the top row of images shows AirSWOT image chips centered around the USGS Calumet station before water masking and outlier filtering.  The bottom row of images shows the height chips after the water masking and outlier filtering  has been applied.\n",
    "\n",
    "Note that there are some parts of the Wax Lake Outlet, such as the upstream portion of the river during the 2021-03-26 flight, which appear as void data, even before our masking and filtering.\n",
    "\n",
    "These void data result from the AirSWOT instrument not receiving enough backscattered radar signal from the water surface to be able to estimate the water surface elevation in these areas.\n",
    "\n",
    "Now, let's load the USGS Calumet station data using Pandas, similarly to the CRMS station data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the USGS station data into Pandas.\n",
    "calumet = pd.read_csv(calumet_station_data_file, sep='\\t', skiprows=29,\n",
    "                      names=['USGS', 'SiteID', 'Datetime', 'TimeZone', 'RawWaterLevel', 'Flag'])\n",
    "\n",
    "# Print the USGS Calumet DataFrame:\n",
    "print(calumet)\n",
    "\n",
    "# Print the columns (field names) of the DataFrame:\n",
    "print(calumet.columns)\n",
    "\n",
    "# Conversion factor from feet to meters.  (USGS Calumet station water levels are in feet.)\n",
    "feet_to_meters = 0.3048\n",
    "\n",
    "# Load the height from the Calumet data and convert it to meters.\n",
    "calumet_hgt = np.array(calumet['RawWaterLevel']) * feet_to_meters\n",
    "\n",
    "# Adjust the height for the datum offset described on the station page: -0.56 ft,\n",
    "# As well as an additional offset because this station was surveyed using a previous version of\n",
    "# the NAVD88 geoid (GEOID96), rather than the newer version (GEOID12B) that we used to convert the\n",
    "# datum of the AirSWOT data.\n",
    "calumet_hgt -= (0.56 * feet_to_meters) # offset to GEOID96 geoid reported on Calumet station information page\n",
    "calumet_hgt -= 0.207 # offset between GEOID96 and GEOID12B at Calumet station location, calculated from VDatum\n",
    "calumet_hgt -= 1.441 # Additional height adjustment because the USGS Calumet station position was surveyed in NAD27.\n",
    "\n",
    "# Load the datetimes.\n",
    "calumet_datetime_str = np.array(calumet['Datetime'])\n",
    "\n",
    "# Track the number of Calumet data records and create an array to store the dates and times as integers.\n",
    "num_of_records = len(calumet_hgt)\n",
    "calumet_datetime_int = np.zeros((num_of_records, 5), dtype='int')\n",
    "\n",
    "# Loop through the dates and times, converting each part (e.g. year, month, day, hour, minute) into an integer.\n",
    "# Note that the format of the data is a little different than the CRMS station.\n",
    "for num, datetime_str in enumerate(calumet_dt_str):\n",
    "    datetime_str = datetime_str.split(' ')\n",
    "    date_str = datetime_str[0]\n",
    "    time_str = datetime_str[1]\n",
    "    \n",
    "    date_str = date_str.split('-')\n",
    "    calumet_datetime_int[num, 0] = int(date_str[0])\n",
    "    calumet_datetime_int[num, 1] = int(date_str[1])\n",
    "    calumet_datetime_int[num, 2] = int(date_str[2])\n",
    "    \n",
    "    time_str = time_str.split(':')\n",
    "    calumet_datetime_int[num, 3] = int(time_str[0])\n",
    "    calumet_datetime_int[num, 4] = int(time_str[1])\n",
    "\n",
    "\n",
    "# The Calumet data is in Central time, while the AirSWOT data is in UTC.\n",
    "# We must therefore either shift the Calumet data forward by five hours, or the AirSWOT data back.\n",
    "# We will shift the Calumet data forward:\n",
    "time_shift = timedelta(hours=5)\n",
    "\n",
    "# Convert the dates and times to Python datetime objects.\n",
    "calumet_datetime = np.empty((num_of_records), dtype=datetime)\n",
    "for num in range(calumet_datetime_int.shape[0]):\n",
    "    calumet_datetime[num] = datetime(calumet_datetime_int[num, 0],\n",
    "                                     calumet_datetime_int[num, 1],\n",
    "                                     calumet_datetime_int[num, 2],\n",
    "                                     calumet_datetime_int[num, 3],\n",
    "                                     calumet_datetime_int[num, 4],\n",
    "                                     0) + time_shift\n",
    "\n",
    "# We do not care about all of the CRMS data in the file.\n",
    "# Let us only consider the period of five days around the time of the AirSWOT acquisition.\n",
    "start_datetime = datetime(2021, 3, 26, 0, 0, 0)\n",
    "end_datetime = datetime(2021, 4, 3, 0, 0, 0)\n",
    "date_range = (calumet_datetime < end_datetime) & (calumet_datetime > start_datetime)\n",
    "\n",
    "# Subset the CRMS data to the desired date range.\n",
    "calumet_datetime = calumet_datetime[date_range]\n",
    "calumet_hgt = calumet_hgt[date_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3aef8",
   "metadata": {},
   "source": [
    "Now that we've loaded the USGS Calumet station data, let's compare the station data to AirSWOT.  This time, our plot shows water surface elevation referenced to the NAVD88 geoid, rather than to the WGS84 ellipsoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the CRMS time series and AirSWOT data.\n",
    "plt.figure()\n",
    "plt.plot(calumet_datetime, calumet_hgt, 'r-', label='USGS Calumet')\n",
    "plt.plot(airswot_datetime, airswot_wse, 'b+', markersize=12, label='AirSWOT')\n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%m %d')\n",
    "plt.gca().xaxis.set_major_formatter(myFmt)\n",
    "plt.title('AirSWOT and CRMS WSE vs. Time')\n",
    "plt.legend(loc='upper right', frameon=True, fontsize=8)\n",
    "xlbl = plt.xlabel('UTC Date')\n",
    "ylbl = plt.ylabel('Water Surface Elevation (m, NAVD88)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ae044",
   "metadata": {},
   "source": [
    "The AirSWOT and USGS Calumet station data correspond fairly well, after the necessary vertical datum transformation have been applied (and after the AirSWOT data has been appropriately masked and filtered).\n",
    "\n",
    "AirSWOT did have a small negative bias compared to the station data during the March 27 flight, but this bias is small (around 5 cm).  Previous efforts to validate AirSWOT data have resulted in AirSWOT root mean square error (RMSE) around 10 cm in most cases.  Therefore, the errors on the above plot are within the expected uncertainty of AirSWOT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd86d38",
   "metadata": {},
   "source": [
    "## Wrapping Up\n",
    "\n",
    "In this module, we covered:\n",
    "\n",
    "1. How to load in situ station data using Pandas, and compare the in situ data to water surface elevations estimated using AirSWOT.\n",
    "2. How to use NOAA VDatum to calculate the vertical offset between different datums.\n",
    "3. How to use GDAL Warp to convert AirSWOT height data from the WGS84 ellipsoid vertical datum to the NAVD88 geoid.\n",
    "\n",
    "This concludes the AirSWOT portion of the Delta-X 2022 Applications Workshop.  We hope this has been interesting and helpful.  If you have questions or feedback on these modules, please feel free to contact Michael Denbina at: michael.w.denbina@jpl.nasa.gov.\n",
    "\n",
    "Thanks for your attention!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
